{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical foundations of Machine Learning\n",
    "\n",
    "## INFO-F-422 TP: Ensembles of models and feature selection\n",
    "\n",
    "Yann-Aël Le Borgne, Fabrizio Carcillo and Gianluca Bontempi\n",
    "\n",
    "May 2, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Ensembles of models and feature selection are two machine learning techniques which can be used to improve the accuracy of preditions. \n",
    "\n",
    "Ensembles of models consist in building several predictive models using resampled subsets of the original training set. The method works particularly well for predictive models with high variance (for example, decision trees or neural networks). The average prediction of the resulting models usually strongly decreases the variance component of the error, and as a consequence improves the prediction accuracy. \n",
    "\n",
    "Feature selection aims at reducing the dimensionality of the problem, and is useful when input variables contain redundant or irrelevant (noisy) information. Benefits are twofold: it decreases the training time by simplifying the problem, and it decreases the complexity of the predictive model. This in turn usually improves the prediction accuracy, since high-dimensionality makes predictive models more prone to overfitting, and estimates of parameters more variant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will illustrate both techniques using the IMDB 5000 dataset, which contains 27 variables describing 5043 movies. The variables contain information about the director, actors, number of Facebook likes for each actor, duration, genre, language, country, etc... We will use them to predict the movie success (through the IMDB score). The dataset together with a description of the variables is at https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset.\n",
    "\n",
    "The dataset is on the github of the course, in datasets/movie_metadata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load and select a random subset of 1000 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(file, \"rt\"):\n",
      "\"impossible d'ouvrir le fichier 'datasets/movie_metadata.csv' : No such file or directory\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): impossible d'ouvrir la connexion\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): impossible d'ouvrir la connexion\nTraceback:\n",
      "1. read.csv(\"datasets/movie_metadata.csv\")",
      "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
      "3. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "data<-read.csv(\"datasets/movie_metadata.csv\")\n",
    "set.seed(2)\n",
    "data<-data[sample(nrow(data),1000),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.matrix.max.cols=50)\n",
    "data[1:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is a mix of categorical and numerical variables, and some missing values. In order to simplify the analysis, let us remove the categorical variables, and replace the NA values with the mean values of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type of input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sapply(data[1,],class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of categorical (factor) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factor_variables<-which(sapply(data[1,],class)==\"factor\")\n",
    "factor_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_preprocessed<-data[,-factor_variables]\n",
    "summary(data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace NA values with mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_na_with_mean_value<-function(vec) {\n",
    "    mean_vec<-mean(vec,na.rm=T)\n",
    "    vec[is.na(vec)]<-mean_vec\n",
    "    vec\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_preprocessed<-data.frame(apply(data_preprocessed,2,replace_na_with_mean_value))\n",
    "summary(data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variable (Y) is the `imdb_score`, and all other variables (X) are considered as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "\n",
    "X<-data_preprocessed[,setdiff(colnames(data_preprocessed),\"imdb_score\")]\n",
    "Y<-data_preprocessed[,\"imdb_score\"]\n",
    "\n",
    "N<-nrow(X)    #Number of examples\n",
    "n<-ncol(X)    #Number of input variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the `imdb_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Modelling with linear and decision tree models\n",
    "\n",
    "#### Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us create a linear model for predicting the IMDB score on the basis of the other variables, and compute its empricial mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS<-cbind(X,imdb_score=Y)\n",
    "    \n",
    "model<- lm(imdb_score~.,DS) ### IMDB score given all the other ones (~.) over the dataset DS\n",
    "\n",
    "Y.hat<- predict(model,X)\n",
    "        \n",
    "empirical_error<-mean((Y.hat-Y)^2) ### MSE for prediction of that model.\n",
    "\n",
    "print(paste(\"Empirical error=\",round(empirical_error,digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which input variables are statistically correlated with the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the validation error with a 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-numeric(10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "     i.ts<-(((i-1)*size.CV+1):(i*size.CV))  ### i.ts = indices of the test set for the i-th fold\n",
    "     X.ts<-X[i.ts,]  \n",
    "     Y.ts<-Y[i.ts]  \n",
    "     \n",
    "     i.tr<-setdiff(1:N,i.ts)                ###i.tr = indices of the training set for the i-th fold\n",
    "     X.tr<-X[i.tr,]\n",
    "     Y.tr<-Y[i.tr]                          \n",
    "     \n",
    "     DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "    \n",
    "     model<- lm(imdb_score~.,DS)      # create model with the training set\n",
    "        \n",
    "     Y.hat.ts<- predict(model,X.ts)  # predict value for the test set\n",
    "        \n",
    "     CV.err[i]<-mean((Y.hat.ts-Y.ts)^2)  # MSE for test set\n",
    "}\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV.err),digits=4), \" ; std dev=\",round(sd(CV.err),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify the previous code to compute the empirical error using a decision tree model. Use the rpart package (see `?rpart` for help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(rpart)       ### Run install.packages(\"rpart\") to install\n",
    "?rpart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DS<-cbind(X,imdb_score=Y)\n",
    "\n",
    "model<- rpart(imdb_score~.,DS)\n",
    "        \n",
    "Y.hat<- predict(model,X)\n",
    "        \n",
    "empirical_error<-mean((Y.hat-Y)^2) \n",
    "\n",
    "print(paste(\"Empirical error=\",round(empirical_error,digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the resulting tree using the `prp` function from the library `rpart.plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(rpart.plot)  ### Run install.packages(\"rpart.plot\") to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prp(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the 10-fold cross-validation error using a decision tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-numeric(10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "     i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "     X.ts<-X[i.ts,]  \n",
    "     Y.ts<-Y[i.ts]  \n",
    "     \n",
    "     i.tr<-setdiff(1:N,i.ts)                \n",
    "     X.tr<-X[i.tr,]\n",
    "     Y.tr<-Y[i.tr]                          \n",
    "     \n",
    "     DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "    \n",
    "     model<- rpart(imdb_score~.,DS)\n",
    "        \n",
    "     Y.hat.ts<- predict(model,X.ts)\n",
    "        \n",
    "     CV.err[i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV.err),digits=4), \" ; std dev=\",round(sd(CV.err),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now create an ensemble of R linear models to make predictions. Complete the code below so that\n",
    "\n",
    "* The training set is resampled before building a model\n",
    "* The predictions of all model are averaged before testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "R<-20   # R models\n",
    "\n",
    "CV.err<-numeric(10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "     i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "     X.ts<-X[i.ts,]  \n",
    "     Y.ts<-Y[i.ts]  \n",
    "     \n",
    "     \n",
    "     i.tr<-setdiff(1:N,i.ts)                \n",
    "    \n",
    "     Y.hat.ts.R<-matrix(0,nrow=nrow(X.ts),ncol=R)\n",
    "    \n",
    "     for (r in 1:R) {\n",
    "         i.tr.resample<-sample(i.tr,rep=T)  #rep = replace\n",
    "         X.tr<-X[i.tr.resample,]\n",
    "         Y.tr<-Y[i.tr.resample]                          \n",
    "     \n",
    "         DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "    \n",
    "         model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "         Y.hat.ts.R[,r]<- predict(model,X.ts)\n",
    "     \n",
    "     }\n",
    "    \n",
    "     Y.hat.ts<-apply(Y.hat.ts.R,1,mean)  #function will be applied over rows (1)\n",
    "     CV.err[i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "     }\n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV.err),digits=4), \" ; std dev=\",round(sd(CV.err),digits=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the CV error lower than with a single linear model?\n",
    "* Use a decision tree as the base model. Is the CV error lower?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature selection\n",
    "\n",
    "Two are the main approaches to feature selection:\n",
    "\n",
    "\n",
    "* **Filter methods:** they are preprocessing methods. They attempt to\n",
    "assess the merits of features from the data, ignoring the effects of\n",
    "the selected feature subset on the performance of the learning\n",
    "algorithm. Examples are methods that select variables by ranking them\n",
    "through compression techniques (like PCA), or by computing correlation or a more advanced similarity measure such as minimum redundancy maximum relevance (mRMR) with the output.\n",
    "\n",
    "*  **Wrapper methods:** these methods assess subsets of variables\n",
    "according to their usefulness to a given predictor. The method\n",
    "conducts a search for a good subset using the learning algorithm\n",
    "itself as part of the evaluation function. The problem boils \n",
    "down to a problem of stochastic state space search. Example\n",
    "are the stepwise methods proposed in linear regression analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with the output\n",
    "\n",
    "* The following code performs features selection by keeping the most correlated variables with the output. Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): objet 'N' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): objet 'N' introuvable\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "     \n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "     \n",
    "    correlation<-abs(cor(X.tr,Y.tr))\n",
    "    ranking<-sort(correlation,dec=T,index.return=T)$ix\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        DS<-cbind(X.tr[,ranking[1:nb_features],drop=F],imdb_score=Y.tr)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        Y.hat.ts<- predict(model,X.ts[,ranking[1:nb_features],drop=F])\n",
    "        \n",
    "        CV.err[nb_features,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV.err,1,mean),digits=4), \" ; std dev=\",round(apply(CV.err,1,sd),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>7</li>\n",
       "\t<li>1</li>\n",
       "\t<li>10</li>\n",
       "\t<li>15</li>\n",
       "\t<li>6</li>\n",
       "\t<li>2</li>\n",
       "\t<li>12</li>\n",
       "\t<li>3</li>\n",
       "\t<li>13</li>\n",
       "\t<li>11</li>\n",
       "\t<li>4</li>\n",
       "\t<li>8</li>\n",
       "\t<li>5</li>\n",
       "\t<li>9</li>\n",
       "\t<li>14</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 7\n",
       "\\item 1\n",
       "\\item 10\n",
       "\\item 15\n",
       "\\item 6\n",
       "\\item 2\n",
       "\\item 12\n",
       "\\item 3\n",
       "\\item 13\n",
       "\\item 11\n",
       "\\item 4\n",
       "\\item 8\n",
       "\\item 5\n",
       "\\item 9\n",
       "\\item 14\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 7\n",
       "2. 1\n",
       "3. 10\n",
       "4. 15\n",
       "5. 6\n",
       "6. 2\n",
       "7. 12\n",
       "8. 3\n",
       "9. 13\n",
       "10. 11\n",
       "11. 4\n",
       "12. 8\n",
       "13. 5\n",
       "14. 9\n",
       "15. 14\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  7  1 10 15  6  2 12  3 13 11  4  8  5  9 14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mRMR\n",
    "\n",
    "* The following code performs features selection by using the mRMR approach (see slides 49-52 of the course http://uv.ulb.ac.be/pluginfile.php/874401/mod_resource/content/2/fsel.pdf). Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): objet 'N' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): objet 'N' introuvable\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "     \n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "    \n",
    "    \n",
    "    correlation<-abs(cor(X.tr,Y.tr))\n",
    "    \n",
    "    selected<-c()\n",
    "    candidates<-1:n\n",
    "    \n",
    "    #mRMR ranks the variables by taking account not only the correlation with the output, but also by avoiding redudant variables\n",
    "    for (j in 1:n) {\n",
    "        redudancy.score<-numeric(length(candidates))\n",
    "        if (length(selected)>0) {\n",
    "            cor.selected.candidates<-cor(X.tr[,selected,drop=F],X.tr[,candidates,drop=F])\n",
    "            redudancy.score<-apply(cor.selected.candidates,2,mean)\n",
    "        }\n",
    "        \n",
    "        mRMR.score<-correlation[candidates]-redudancy.score\n",
    "        \n",
    "        selected_current<-candidates[which.max(mRMR.score)]\n",
    "        selected<-c(selected,selected_current)\n",
    "        candidates<-setdiff(candidates,selected_current)\n",
    "    }\n",
    "    \n",
    "    ranking<-selected\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        DS<-cbind(X.tr[,ranking[1:nb_features],drop=F],imdb_score=Y.tr)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        Y.hat.ts<- predict(model,X.ts[,ranking[1:nb_features],drop=F])\n",
    "        \n",
    "        CV.err[nb_features,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV.err,1,mean),digits=4), \" ; std dev=\",round(apply(CV.err,1,sd),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>7</li>\n",
       "\t<li>12</li>\n",
       "\t<li>2</li>\n",
       "\t<li>9</li>\n",
       "\t<li>3</li>\n",
       "\t<li>1</li>\n",
       "\t<li>14</li>\n",
       "\t<li>10</li>\n",
       "\t<li>15</li>\n",
       "\t<li>5</li>\n",
       "\t<li>6</li>\n",
       "\t<li>13</li>\n",
       "\t<li>4</li>\n",
       "\t<li>11</li>\n",
       "\t<li>8</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 7\n",
       "\\item 12\n",
       "\\item 2\n",
       "\\item 9\n",
       "\\item 3\n",
       "\\item 1\n",
       "\\item 14\n",
       "\\item 10\n",
       "\\item 15\n",
       "\\item 5\n",
       "\\item 6\n",
       "\\item 13\n",
       "\\item 4\n",
       "\\item 11\n",
       "\\item 8\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 7\n",
       "2. 12\n",
       "3. 2\n",
       "4. 9\n",
       "5. 3\n",
       "6. 1\n",
       "7. 14\n",
       "8. 10\n",
       "9. 15\n",
       "10. 5\n",
       "11. 6\n",
       "12. 13\n",
       "13. 4\n",
       "14. 11\n",
       "15. 8\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  7 12  2  9  3  1 14 10 15  5  6 13  4 11  8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "* The following code performs features selection by first transforming the inputs using PCA, and then keeping the most relevant principal components in the model. Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"#Features:  1  ; CV error= 1.2051  ; std dev= 0.1211\" \n",
      " [2] \"#Features:  2  ; CV error= 1.199  ; std dev= 0.1282\"  \n",
      " [3] \"#Features:  3  ; CV error= 0.9963  ; std dev= 0.081\"  \n",
      " [4] \"#Features:  4  ; CV error= 1.0043  ; std dev= 0.0777\" \n",
      " [5] \"#Features:  5  ; CV error= 1.0046  ; std dev= 0.0815\" \n",
      " [6] \"#Features:  6  ; CV error= 1.0084  ; std dev= 0.0818\" \n",
      " [7] \"#Features:  7  ; CV error= 1.0063  ; std dev= 0.0753\" \n",
      " [8] \"#Features:  8  ; CV error= 0.9993  ; std dev= 0.0871\" \n",
      " [9] \"#Features:  9  ; CV error= 1.002  ; std dev= 0.0925\"  \n",
      "[10] \"#Features:  10  ; CV error= 1.0025  ; std dev= 0.095\" \n",
      "[11] \"#Features:  11  ; CV error= 0.9773  ; std dev= 0.1005\"\n",
      "[12] \"#Features:  12  ; CV error= 0.9661  ; std dev= 0.1263\"\n",
      "[13] \"#Features:  13  ; CV error= 0.9142  ; std dev= 0.1412\"\n",
      "[14] \"#Features:  14  ; CV error= 0.9157  ; std dev= 0.1426\"\n",
      "[15] \"#Features:  15  ; CV error= 0.9138  ; std dev= 0.1508\"\n"
     ]
    }
   ],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "X_pca<-data.frame(prcomp(X,retx=T)$x)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X_pca[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "     \n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X_pca[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        DS<-cbind(X.tr[,1:nb_features,drop=F],imdb_score=Y.tr)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        Y.hat.ts<- predict(model,X.ts[,1:nb_features,drop=F])\n",
    "        \n",
    "        CV.err[nb_features,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV.err,1,mean),digits=4), \" ; std dev=\",round(apply(CV.err,1,sd),digits=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper method: Forward selection\n",
    "\n",
    "* The following code performs features selection by using a forward selection method (See slide 20 in http://uv.ulb.ac.be/pluginfile.php/874401/mod_resource/content/1/fsel.pdf). Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Round  1  ; Selected feature:  7  ; CV error= 1.0018  ; std dev= 0.0678\"\n",
      "[1] \"Round  2  ; Selected feature:  12  ; CV error= 0.9618  ; std dev= 0.081\"\n",
      "[1] \"Round  3  ; Selected feature:  1  ; CV error= 0.9261  ; std dev= 0.0961\"\n",
      "[1] \"Round  4  ; Selected feature:  10  ; CV error= 0.912  ; std dev= 0.1088\"\n",
      "[1] \"Round  5  ; Selected feature:  11  ; CV error= 0.9062  ; std dev= 0.1085\"\n",
      "[1] \"Round  6  ; Selected feature:  2  ; CV error= 0.9016  ; std dev= 0.1243\"\n",
      "[1] \"Round  7  ; Selected feature:  14  ; CV error= 0.9004  ; std dev= 0.1337\"\n",
      "[1] \"Round  8  ; Selected feature:  4  ; CV error= 0.9  ; std dev= 0.1361\"\n",
      "[1] \"Round  9  ; Selected feature:  13  ; CV error= 0.8989  ; std dev= 0.1372\"\n",
      "[1] \"Round  10  ; Selected feature:  6  ; CV error= 0.899  ; std dev= 0.1342\"\n",
      "[1] \"Round  11  ; Selected feature:  3  ; CV error= 0.8992  ; std dev= 0.1333\"\n",
      "[1] \"Round  12  ; Selected feature:  15  ; CV error= 0.8996  ; std dev= 0.1336\"\n",
      "[1] \"Round  13  ; Selected feature:  9  ; CV error= 0.9017  ; std dev= 0.1355\"\n",
      "[1] \"Round  14  ; Selected feature:  8  ; CV error= 0.9078  ; std dev= 0.1331\"\n",
      "[1] \"Round  15  ; Selected feature:  5  ; CV error= 0.9138  ; std dev= 0.1508\"\n"
     ]
    }
   ],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "selected<-NULL\n",
    "\n",
    "for (round in 1:n) { \n",
    "    candidates<-setdiff(1:n,selected)\n",
    "    \n",
    "    CV.err<-matrix(0,nrow=length(candidates),ncol=10)\n",
    "    \n",
    "    for (j in 1:length(candidates)) {\n",
    "        features_to_include<-c(selected,candidates[j])\n",
    "        \n",
    "        for (i in 1:10) {\n",
    "            i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "            X.ts<-X[i.ts,features_to_include,drop=F]  \n",
    "            Y.ts<-Y[i.ts]  \n",
    "     \n",
    "            i.tr<-setdiff(1:N,i.ts)\n",
    "            X.tr<-X[i.tr,features_to_include,drop=F]\n",
    "            Y.tr<-Y[i.tr]\n",
    "     \n",
    "            DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "            model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "            Y.hat.ts<- predict(model,X.ts)\n",
    "        \n",
    "            CV.err[j,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "        }\n",
    "    }\n",
    "    CV.err.mean<-apply(CV.err,1,mean)\n",
    "    CV.err.sd<-apply(CV.err,1,sd)\n",
    "    selected_current<-which.min(CV.err.mean)              \n",
    "    selected<-c(selected,candidates[selected_current])\n",
    "    print(paste(\"Round \",round,\" ; Selected feature: \",candidates[selected_current],\" ; CV error=\",round(CV.err.mean[selected_current],digits=4), \" ; std dev=\",round(CV.err.sd[selected_current],digits=4)))\n",
    "\n",
    "}\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'num_voted_users'</li>\n",
       "\t<li>'title_year'</li>\n",
       "\t<li>'num_critic_for_reviews'</li>\n",
       "\t<li>'num_user_for_reviews'</li>\n",
       "\t<li>'budget'</li>\n",
       "\t<li>'duration'</li>\n",
       "\t<li>'aspect_ratio'</li>\n",
       "\t<li>'actor_3_facebook_likes'</li>\n",
       "\t<li>'actor_2_facebook_likes'</li>\n",
       "\t<li>'gross'</li>\n",
       "\t<li>'director_facebook_likes'</li>\n",
       "\t<li>'movie_facebook_likes'</li>\n",
       "\t<li>'facenumber_in_poster'</li>\n",
       "\t<li>'cast_total_facebook_likes'</li>\n",
       "\t<li>'actor_1_facebook_likes'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_voted\\_users'\n",
       "\\item 'title\\_year'\n",
       "\\item 'num\\_critic\\_for\\_reviews'\n",
       "\\item 'num\\_user\\_for\\_reviews'\n",
       "\\item 'budget'\n",
       "\\item 'duration'\n",
       "\\item 'aspect\\_ratio'\n",
       "\\item 'actor\\_3\\_facebook\\_likes'\n",
       "\\item 'actor\\_2\\_facebook\\_likes'\n",
       "\\item 'gross'\n",
       "\\item 'director\\_facebook\\_likes'\n",
       "\\item 'movie\\_facebook\\_likes'\n",
       "\\item 'facenumber\\_in\\_poster'\n",
       "\\item 'cast\\_total\\_facebook\\_likes'\n",
       "\\item 'actor\\_1\\_facebook\\_likes'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_voted_users'\n",
       "2. 'title_year'\n",
       "3. 'num_critic_for_reviews'\n",
       "4. 'num_user_for_reviews'\n",
       "5. 'budget'\n",
       "6. 'duration'\n",
       "7. 'aspect_ratio'\n",
       "8. 'actor_3_facebook_likes'\n",
       "9. 'actor_2_facebook_likes'\n",
       "10. 'gross'\n",
       "11. 'director_facebook_likes'\n",
       "12. 'movie_facebook_likes'\n",
       "13. 'facenumber_in_poster'\n",
       "14. 'cast_total_facebook_likes'\n",
       "15. 'actor_1_facebook_likes'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_voted_users\"           \"title_year\"               \n",
       " [3] \"num_critic_for_reviews\"    \"num_user_for_reviews\"     \n",
       " [5] \"budget\"                    \"duration\"                 \n",
       " [7] \"aspect_ratio\"              \"actor_3_facebook_likes\"   \n",
       " [9] \"actor_2_facebook_likes\"    \"gross\"                    \n",
       "[11] \"director_facebook_likes\"   \"movie_facebook_likes\"     \n",
       "[13] \"facenumber_in_poster\"      \"cast_total_facebook_likes\"\n",
       "[15] \"actor_1_facebook_likes\"   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(X)[selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further preprocessing to add categorical variables\n",
    "\n",
    "Categorical variables usually need to be transformed with 'one-hot-encoding' in order to be processed by a learning algorithm. That is, for each value of the categorical variable, a binary feature is created, which is set to one whenever that value is present. This can be done using the `dummy.data.frame` of the `dummies` package.\n",
    "\n",
    "```\n",
    "install.packages('dummies')\n",
    "library(dummies)\n",
    "```\n",
    "\n",
    "In the following, we add some categorical variables to the peprocessing dataset. The set of categorical variables is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dummies-1.5.6 provided by Decision Patterns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>color</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>director_name</dt>\n",
       "\t\t<dd>2</dd>\n",
       "\t<dt>actor_2_name</dt>\n",
       "\t\t<dd>7</dd>\n",
       "\t<dt>genres</dt>\n",
       "\t\t<dd>10</dd>\n",
       "\t<dt>actor_1_name</dt>\n",
       "\t\t<dd>11</dd>\n",
       "\t<dt>movie_title</dt>\n",
       "\t\t<dd>12</dd>\n",
       "\t<dt>actor_3_name</dt>\n",
       "\t\t<dd>15</dd>\n",
       "\t<dt>plot_keywords</dt>\n",
       "\t\t<dd>17</dd>\n",
       "\t<dt>movie_imdb_link</dt>\n",
       "\t\t<dd>18</dd>\n",
       "\t<dt>language</dt>\n",
       "\t\t<dd>20</dd>\n",
       "\t<dt>country</dt>\n",
       "\t\t<dd>21</dd>\n",
       "\t<dt>content_rating</dt>\n",
       "\t\t<dd>22</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[color] 1\n",
       "\\item[director\\textbackslash{}\\_name] 2\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_name] 7\n",
       "\\item[genres] 10\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_name] 11\n",
       "\\item[movie\\textbackslash{}\\_title] 12\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_name] 15\n",
       "\\item[plot\\textbackslash{}\\_keywords] 17\n",
       "\\item[movie\\textbackslash{}\\_imdb\\textbackslash{}\\_link] 18\n",
       "\\item[language] 20\n",
       "\\item[country] 21\n",
       "\\item[content\\textbackslash{}\\_rating] 22\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "color\n",
       ":   1director_name\n",
       ":   2actor_2_name\n",
       ":   7genres\n",
       ":   10actor_1_name\n",
       ":   11movie_title\n",
       ":   12actor_3_name\n",
       ":   15plot_keywords\n",
       ":   17movie_imdb_link\n",
       ":   18language\n",
       ":   20country\n",
       ":   21content_rating\n",
       ":   22\n",
       "\n"
      ],
      "text/plain": [
       "          color   director_name    actor_2_name          genres    actor_1_name \n",
       "              1               2               7              10              11 \n",
       "    movie_title    actor_3_name   plot_keywords movie_imdb_link        language \n",
       "             12              15              17              18              20 \n",
       "        country  content_rating \n",
       "             21              22 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factor_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have an overview of the their content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_factor<-data[,factor_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>12</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 12\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 12\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>color</th><th scope=col>director_name</th><th scope=col>actor_2_name</th><th scope=col>genres</th><th scope=col>actor_1_name</th><th scope=col>movie_title</th><th scope=col>actor_3_name</th><th scope=col>plot_keywords</th><th scope=col>movie_imdb_link</th><th scope=col>language</th><th scope=col>country</th><th scope=col>content_rating</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>933</th><td>Color                                               </td><td>James L. Brooks                                     </td><td>Yeardley Smith                                      </td><td>Comedy|Drama|Romance                                </td><td>Lupe Ontiveros                                      </td><td>As Good as It Gets<c2><a0>                          </td><td>Shirley Knight                                      </td><td>dog|friendship|neighbor|unlikely friendship|writer  </td><td>http://www.imdb.com/title/tt0119822/?ref_=fn_tt_tt_1</td><td>English                                             </td><td>USA                                                 </td><td>PG-13                                               </td></tr>\n",
       "\t<tr><th scope=row>3542</th><td>Color                                               </td><td>Robert C. Cooper                                    </td><td>Christopher Judge                                   </td><td>Action|Adventure|Drama|Fantasy|Sci-Fi               </td><td>Ben Browder                                         </td><td>Stargate: The Ark of Truth<c2><a0>                  </td><td>Julian Sands                                        </td><td>2000s|evil god|space opera|stargate|wormhole        </td><td>http://www.imdb.com/title/tt0942903/?ref_=fn_tt_tt_1</td><td>English                                             </td><td>USA                                                 </td><td>                                                    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllll}\n",
       "  & color & director\\_name & actor\\_2\\_name & genres & actor\\_1\\_name & movie\\_title & actor\\_3\\_name & plot\\_keywords & movie\\_imdb\\_link & language & country & content\\_rating\\\\\n",
       "\\hline\n",
       "\t933 & Color                                                                                      & James L. Brooks                                                                            & Yeardley Smith                                                                             & Comedy\\textbar{}Drama\\textbar{}Romance                                                   & Lupe Ontiveros                                                                             & As Good as It Gets<c2><a0>                                                                 & Shirley Knight                                                                             & dog\\textbar{}friendship\\textbar{}neighbor\\textbar{}unlikely friendship\\textbar{}writer & http://www.imdb.com/title/tt0119822/?ref\\_=fn\\_tt\\_tt\\_1                               & English                                                                                    & USA                                                                                        & PG-13                                                                                     \\\\\n",
       "\t3542 & Color                                                                                      & Robert C. Cooper                                                                           & Christopher Judge                                                                          & Action\\textbar{}Adventure\\textbar{}Drama\\textbar{}Fantasy\\textbar{}Sci-Fi              & Ben Browder                                                                                & Stargate: The Ark of Truth<c2><a0>                                                         & Julian Sands                                                                               & 2000s\\textbar{}evil god\\textbar{}space opera\\textbar{}stargate\\textbar{}wormhole       & http://www.imdb.com/title/tt0942903/?ref\\_=fn\\_tt\\_tt\\_1                               & English                                                                                    & USA                                                                                        &                                                                                           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | color | director_name | actor_2_name | genres | actor_1_name | movie_title | actor_3_name | plot_keywords | movie_imdb_link | language | country | content_rating | \n",
       "|---|---|\n",
       "| 933 | Color                                                | James L. Brooks                                      | Yeardley Smith                                       | Comedy|Drama|Romance                                 | Lupe Ontiveros                                       | As Good as It Gets<c2><a0>                           | Shirley Knight                                       | dog|friendship|neighbor|unlikely friendship|writer   | http://www.imdb.com/title/tt0119822/?ref_=fn_tt_tt_1 | English                                              | USA                                                  | PG-13                                                | \n",
       "| 3542 | Color                                                | Robert C. Cooper                                     | Christopher Judge                                    | Action|Adventure|Drama|Fantasy|Sci-Fi                | Ben Browder                                          | Stargate: The Ark of Truth<c2><a0>                   | Julian Sands                                         | 2000s|evil god|space opera|stargate|wormhole         | http://www.imdb.com/title/tt0942903/?ref_=fn_tt_tt_1 | English                                              | USA                                                  |                                                      | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     color director_name    actor_2_name     \n",
       "933  Color James L. Brooks  Yeardley Smith   \n",
       "3542 Color Robert C. Cooper Christopher Judge\n",
       "     genres                                actor_1_name  \n",
       "933  Comedy|Drama|Romance                  Lupe Ontiveros\n",
       "3542 Action|Adventure|Drama|Fantasy|Sci-Fi Ben Browder   \n",
       "     movie_title                        actor_3_name  \n",
       "933  As Good as It Gets\\302\\240         Shirley Knight\n",
       "3542 Stargate: The Ark of Truth\\302\\240 Julian Sands  \n",
       "     plot_keywords                                     \n",
       "933  dog|friendship|neighbor|unlikely friendship|writer\n",
       "3542 2000s|evil god|space opera|stargate|wormhole      \n",
       "     movie_imdb_link                                      language country\n",
       "933  http://www.imdb.com/title/tt0119822/?ref_=fn_tt_tt_1 English  USA    \n",
       "3542 http://www.imdb.com/title/tt0942903/?ref_=fn_tt_tt_1 English  USA    \n",
       "     content_rating\n",
       "933  PG-13         \n",
       "3542               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_factor[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us keep four of them: Color, language, country and content_rating, and transform them with one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_to_keep<-c(\"color\",\"language\",\"country\",\"content_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_factor_onehot <- dummy.data.frame(data_factor[,variable_to_keep], sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>76</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 76\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 76\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>color_</th><th scope=col>color_ Black and White</th><th scope=col>color_Color</th><th scope=col>language_</th><th scope=col>language_Aboriginal</th><th scope=col>language_Arabic</th><th scope=col>language_Bosnian</th><th scope=col>language_Cantonese</th><th scope=col>language_Dutch</th><th scope=col>language_English</th><th scope=col>language_French</th><th scope=col>language_German</th><th scope=col>language_Hebrew</th><th scope=col>language_Hindi</th><th scope=col>language_Icelandic</th><th scope=col>language_Italian</th><th scope=col>language_Japanese</th><th scope=col>language_Mandarin</th><th scope=col>language_Mongolian</th><th scope=col>language_Persian</th><th scope=col>language_Polish</th><th scope=col>language_Portuguese</th><th scope=col>language_Spanish</th><th scope=col>language_Swahili</th><th scope=col>language_Swedish</th><th scope=col>⋯</th><th scope=col>country_Peru</th><th scope=col>country_Poland</th><th scope=col>country_Russia</th><th scope=col>country_South Korea</th><th scope=col>country_Spain</th><th scope=col>country_Sweden</th><th scope=col>country_UK</th><th scope=col>country_USA</th><th scope=col>country_United Arab Emirates</th><th scope=col>content_rating_</th><th scope=col>content_rating_Approved</th><th scope=col>content_rating_G</th><th scope=col>content_rating_M</th><th scope=col>content_rating_NC-17</th><th scope=col>content_rating_Not Rated</th><th scope=col>content_rating_PG</th><th scope=col>content_rating_PG-13</th><th scope=col>content_rating_Passed</th><th scope=col>content_rating_R</th><th scope=col>content_rating_TV-14</th><th scope=col>content_rating_TV-G</th><th scope=col>content_rating_TV-MA</th><th scope=col>content_rating_TV-PG</th><th scope=col>content_rating_Unrated</th><th scope=col>content_rating_X</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>933</th><td>0       </td><td>0       </td><td>1       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td><U+22EF></td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td></tr>\n",
       "\t<tr><th scope=row>3542</th><td>0       </td><td>0       </td><td>1       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td><U+22EF></td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1       </td><td>0       </td><td>1       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "  & color\\_ & color\\_ Black and White & color\\_Color & language\\_ & language\\_Aboriginal & language\\_Arabic & language\\_Bosnian & language\\_Cantonese & language\\_Dutch & language\\_English & language\\_French & language\\_German & language\\_Hebrew & language\\_Hindi & language\\_Icelandic & language\\_Italian & language\\_Japanese & language\\_Mandarin & language\\_Mongolian & language\\_Persian & language\\_Polish & language\\_Portuguese & language\\_Spanish & language\\_Swahili & language\\_Swedish & ⋯ & country\\_Peru & country\\_Poland & country\\_Russia & country\\_South Korea & country\\_Spain & country\\_Sweden & country\\_UK & country\\_USA & country\\_United Arab Emirates & content\\_rating\\_ & content\\_rating\\_Approved & content\\_rating\\_G & content\\_rating\\_M & content\\_rating\\_NC-17 & content\\_rating\\_Not Rated & content\\_rating\\_PG & content\\_rating\\_PG-13 & content\\_rating\\_Passed & content\\_rating\\_R & content\\_rating\\_TV-14 & content\\_rating\\_TV-G & content\\_rating\\_TV-MA & content\\_rating\\_TV-PG & content\\_rating\\_Unrated & content\\_rating\\_X\\\\\n",
       "\\hline\n",
       "\t933 & 0        & 0        & 1        & 0        & 0        & 0        & 0        & 0        & 0        & 1        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & <U+22EF> & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 1        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 1        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0       \\\\\n",
       "\t3542 & 0        & 0        & 1        & 0        & 0        & 0        & 0        & 0        & 0        & 1        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & <U+22EF> & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 1        & 0        & 1        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0        & 0       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | color_ | color_ Black and White | color_Color | language_ | language_Aboriginal | language_Arabic | language_Bosnian | language_Cantonese | language_Dutch | language_English | language_French | language_German | language_Hebrew | language_Hindi | language_Icelandic | language_Italian | language_Japanese | language_Mandarin | language_Mongolian | language_Persian | language_Polish | language_Portuguese | language_Spanish | language_Swahili | language_Swedish | ⋯ | country_Peru | country_Poland | country_Russia | country_South Korea | country_Spain | country_Sweden | country_UK | country_USA | country_United Arab Emirates | content_rating_ | content_rating_Approved | content_rating_G | content_rating_M | content_rating_NC-17 | content_rating_Not Rated | content_rating_PG | content_rating_PG-13 | content_rating_Passed | content_rating_R | content_rating_TV-14 | content_rating_TV-G | content_rating_TV-MA | content_rating_TV-PG | content_rating_Unrated | content_rating_X | \n",
       "|---|---|\n",
       "| 933 | 0        | 0        | 1        | 0        | 0        | 0        | 0        | 0        | 0        | 1        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | <U+22EF> | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 1        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 1        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | \n",
       "| 3542 | 0        | 0        | 1        | 0        | 0        | 0        | 0        | 0        | 0        | 1        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | <U+22EF> | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 1        | 0        | 1        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     color_ color_ Black and White color_Color language_ language_Aboriginal\n",
       "933  0      0                      1           0         0                  \n",
       "3542 0      0                      1           0         0                  \n",
       "     language_Arabic language_Bosnian language_Cantonese language_Dutch\n",
       "933  0               0                0                  0             \n",
       "3542 0               0                0                  0             \n",
       "     language_English language_French language_German language_Hebrew\n",
       "933  1                0               0               0              \n",
       "3542 1                0               0               0              \n",
       "     language_Hindi language_Icelandic language_Italian language_Japanese\n",
       "933  0              0                  0                0                \n",
       "3542 0              0                  0                0                \n",
       "     language_Mandarin language_Mongolian language_Persian language_Polish\n",
       "933  0                 0                  0                0              \n",
       "3542 0                 0                  0                0              \n",
       "     language_Portuguese language_Spanish language_Swahili language_Swedish\n",
       "933  0                   0                0                0               \n",
       "3542 0                   0                0                0               \n",
       "     <U+22EF>   country_Peru country_Poland country_Russia country_South Korea\n",
       "933  <U+22EF> 0            0              0              0                  \n",
       "3542 <U+22EF> 0            0              0              0                  \n",
       "     country_Spain country_Sweden country_UK country_USA\n",
       "933  0             0              0          1          \n",
       "3542 0             0              0          1          \n",
       "     country_United Arab Emirates content_rating_ content_rating_Approved\n",
       "933  0                            0               0                      \n",
       "3542 0                            1               0                      \n",
       "     content_rating_G content_rating_M content_rating_NC-17\n",
       "933  0                0                0                   \n",
       "3542 0                0                0                   \n",
       "     content_rating_Not Rated content_rating_PG content_rating_PG-13\n",
       "933  0                        0                 1                   \n",
       "3542 0                        0                 0                   \n",
       "     content_rating_Passed content_rating_R content_rating_TV-14\n",
       "933  0                     0                0                   \n",
       "3542 0                     0                0                   \n",
       "     content_rating_TV-G content_rating_TV-MA content_rating_TV-PG\n",
       "933  0                   0                    0                   \n",
       "3542 0                   0                    0                   \n",
       "     content_rating_Unrated content_rating_X\n",
       "933  0                      0               \n",
       "3542 0                      0               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_factor_onehot[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These could be added to the previously preprocessed dataset, and used to further improve the prediction accuracy using the feature selection/ensemble techniques seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_preprocessed_extended<-cbind(data_preprocessed,data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>92</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 92\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 92\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   92"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " num_critic_for_reviews    duration     director_facebook_likes\n",
       " Min.   :  1.0          Min.   : 11.0   Min.   :    0.0        \n",
       " 1st Qu.: 50.0          1st Qu.: 93.0   1st Qu.:    7.0        \n",
       " Median :110.0          Median :104.0   Median :   47.5        \n",
       " Mean   :143.5          Mean   :107.7   Mean   :  735.7        \n",
       " 3rd Qu.:199.0          3rd Qu.:118.0   3rd Qu.:  210.5        \n",
       " Max.   :813.0          Max.   :511.0   Max.   :22000.0        \n",
       " actor_3_facebook_likes actor_1_facebook_likes     gross          \n",
       " Min.   :    0.0        Min.   :     0.0       Min.   :     1332  \n",
       " 1st Qu.:  123.8        1st Qu.:   591.8       1st Qu.:  9709388  \n",
       " Median :  366.0        Median :   984.5       Median : 39670256  \n",
       " Mean   :  618.1        Mean   :  6594.5       Mean   : 52916026  \n",
       " 3rd Qu.:  635.5        3rd Qu.: 11000.0       3rd Qu.: 54422773  \n",
       " Max.   :23000.0        Max.   :260000.0       Max.   :533316061  \n",
       " num_voted_users   cast_total_facebook_likes facenumber_in_poster\n",
       " Min.   :     13   Min.   :     0            Min.   : 0.000      \n",
       " 1st Qu.:   8143   1st Qu.:  1344            1st Qu.: 0.000      \n",
       " Median :  31808   Median :  2982            Median : 1.000      \n",
       " Mean   :  93131   Mean   :  9696            Mean   : 1.422      \n",
       " 3rd Qu.: 102979   3rd Qu.: 13766            3rd Qu.: 2.000      \n",
       " Max.   :1689764   Max.   :283939            Max.   :43.000      \n",
       " num_user_for_reviews     budget            title_year   actor_2_facebook_likes\n",
       " Min.   :   1.0       Min.   :    10000   Min.   :1929   Min.   :    0.0       \n",
       " 1st Qu.:  64.0       1st Qu.:  7000000   1st Qu.:1999   1st Qu.:  289.5       \n",
       " Median : 150.0       Median : 23000000   Median :2005   Median :  611.5       \n",
       " Mean   : 285.8       Mean   : 34077007   Mean   :2003   Mean   : 1664.6       \n",
       " 3rd Qu.: 340.0       3rd Qu.: 40000000   3rd Qu.:2011   3rd Qu.:  909.0       \n",
       " Max.   :4667.0       Max.   :258000000   Max.   :2016   Max.   :25000.0       \n",
       "   imdb_score     aspect_ratio    movie_facebook_likes     color_     \n",
       " Min.   :1.600   Min.   : 1.180   Min.   :     0       Min.   :0.000  \n",
       " 1st Qu.:5.800   1st Qu.: 1.850   1st Qu.:     0       1st Qu.:0.000  \n",
       " Median :6.600   Median : 2.205   Median :   182       Median :0.000  \n",
       " Mean   :6.454   Mean   : 2.205   Mean   :  8375       Mean   :0.005  \n",
       " 3rd Qu.:7.200   3rd Qu.: 2.350   3rd Qu.:  2000       3rd Qu.:0.000  \n",
       " Max.   :9.300   Max.   :16.000   Max.   :199000       Max.   :1.000  \n",
       " color_ Black and White  color_Color      language_     language_Aboriginal\n",
       " Min.   :0.000          Min.   :0.000   Min.   :0.000   Min.   :0.000      \n",
       " 1st Qu.:0.000          1st Qu.:1.000   1st Qu.:0.000   1st Qu.:0.000      \n",
       " Median :0.000          Median :1.000   Median :0.000   Median :0.000      \n",
       " Mean   :0.046          Mean   :0.949   Mean   :0.001   Mean   :0.001      \n",
       " 3rd Qu.:0.000          3rd Qu.:1.000   3rd Qu.:0.000   3rd Qu.:0.000      \n",
       " Max.   :1.000          Max.   :1.000   Max.   :1.000   Max.   :1.000      \n",
       " language_Arabic language_Bosnian language_Cantonese language_Dutch \n",
       " Min.   :0.000   Min.   :0.000    Min.   :0.000      Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000    1st Qu.:0.000      1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000    Median :0.000      Median :0.000  \n",
       " Mean   :0.001   Mean   :0.001    Mean   :0.005      Mean   :0.001  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000    3rd Qu.:0.000      3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000    Max.   :1.000      Max.   :1.000  \n",
       " language_English language_French language_German language_Hebrew\n",
       " Min.   :0.000    Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:1.000    1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :1.000    Median :0.000   Median :0.000   Median :0.000  \n",
       " Mean   :0.945    Mean   :0.011   Mean   :0.003   Mean   :0.001  \n",
       " 3rd Qu.:1.000    3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000    Max.   :1.000   Max.   :1.000   Max.   :1.000  \n",
       " language_Hindi  language_Icelandic language_Italian language_Japanese\n",
       " Min.   :0.000   Min.   :0.000      Min.   :0.000    Min.   :0.000    \n",
       " 1st Qu.:0.000   1st Qu.:0.000      1st Qu.:0.000    1st Qu.:0.000    \n",
       " Median :0.000   Median :0.000      Median :0.000    Median :0.000    \n",
       " Mean   :0.005   Mean   :0.001      Mean   :0.003    Mean   :0.004    \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000      3rd Qu.:0.000    3rd Qu.:0.000    \n",
       " Max.   :1.000   Max.   :1.000      Max.   :1.000    Max.   :1.000    \n",
       " language_Mandarin language_Mongolian language_Persian language_Polish\n",
       " Min.   :0.000     Min.   :0.000      Min.   :0.000    Min.   :0.000  \n",
       " 1st Qu.:0.000     1st Qu.:0.000      1st Qu.:0.000    1st Qu.:0.000  \n",
       " Median :0.000     Median :0.000      Median :0.000    Median :0.000  \n",
       " Mean   :0.004     Mean   :0.001      Mean   :0.001    Mean   :0.001  \n",
       " 3rd Qu.:0.000     3rd Qu.:0.000      3rd Qu.:0.000    3rd Qu.:0.000  \n",
       " Max.   :1.000     Max.   :1.000      Max.   :1.000    Max.   :1.000  \n",
       " language_Portuguese language_Spanish language_Swahili language_Swedish\n",
       " Min.   :0.000       Min.   :0.000    Min.   :0.000    Min.   :0.000   \n",
       " 1st Qu.:0.000       1st Qu.:0.000    1st Qu.:0.000    1st Qu.:0.000   \n",
       " Median :0.000       Median :0.000    Median :0.000    Median :0.000   \n",
       " Mean   :0.001       Mean   :0.005    Mean   :0.001    Mean   :0.003   \n",
       " 3rd Qu.:0.000       3rd Qu.:0.000    3rd Qu.:0.000    3rd Qu.:0.000   \n",
       " Max.   :1.000       Max.   :1.000    Max.   :1.000    Max.   :1.000   \n",
       "    country_     country_Australia country_Bahamas country_Belgium\n",
       " Min.   :0.000   Min.   :0.000     Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000     1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000     Median :0.000   Median :0.000  \n",
       " Mean   :0.001   Mean   :0.011     Mean   :0.001   Mean   :0.001  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000     3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000     Max.   :1.000   Max.   :1.000  \n",
       " country_Brazil  country_Cameroon country_Canada  country_China  \n",
       " Min.   :0.000   Min.   :0.000    Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000    1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000    Median :0.000   Median :0.000  \n",
       " Mean   :0.001   Mean   :0.001    Mean   :0.023   Mean   :0.008  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000    3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000    Max.   :1.000   Max.   :1.000  \n",
       " country_France  country_Georgia country_Germany country_Greece \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000   Median :0.000   Median :0.000  \n",
       " Mean   :0.023   Mean   :0.001   Mean   :0.017   Mean   :0.001  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000   Max.   :1.000  \n",
       " country_Hong Kong country_Iceland country_India    country_Iran  \n",
       " Min.   :0.000     Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000     1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000     Median :0.000   Median :0.000   Median :0.000  \n",
       " Mean   :0.004     Mean   :0.002   Mean   :0.008   Mean   :0.001  \n",
       " 3rd Qu.:0.000     3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000     Max.   :1.000   Max.   :1.000   Max.   :1.000  \n",
       " country_Ireland country_Israel  country_Italy   country_Japan  \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000   Median :0.000   Median :0.000  \n",
       " Mean   :0.001   Mean   :0.001   Mean   :0.002   Mean   :0.007  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000   Max.   :1.000  \n",
       " country_Kenya   country_Mexico  country_Netherlands country_New Zealand\n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000       Min.   :0.000      \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000       1st Qu.:0.000      \n",
       " Median :0.000   Median :0.000   Median :0.000       Median :0.000      \n",
       " Mean   :0.001   Mean   :0.003   Mean   :0.001       Mean   :0.003      \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000       3rd Qu.:0.000      \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000       Max.   :1.000      \n",
       " country_Nigeria country_Norway   country_Peru   country_Poland \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000   Median :0.000   Median :0.000  \n",
       " Mean   :0.001   Mean   :0.001   Mean   :0.001   Mean   :0.001  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000   Max.   :1.000  \n",
       " country_Russia  country_South Korea country_Spain   country_Sweden \n",
       " Min.   :0.000   Min.   :0.000       Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000       1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000       Median :0.000   Median :0.000  \n",
       " Mean   :0.001   Mean   :0.001       Mean   :0.003   Mean   :0.003  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000       3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000       Max.   :1.000   Max.   :1.000  \n",
       "   country_UK     country_USA    country_United Arab Emirates content_rating_\n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000                Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:1.000   1st Qu.:0.000                1st Qu.:0.000  \n",
       " Median :0.000   Median :1.000   Median :0.000                Median :0.000  \n",
       " Mean   :0.102   Mean   :0.762   Mean   :0.001                Mean   :0.059  \n",
       " 3rd Qu.:0.000   3rd Qu.:1.000   3rd Qu.:0.000                3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000                Max.   :1.000  \n",
       " content_rating_Approved content_rating_G content_rating_M content_rating_NC-17\n",
       " Min.   :0.000           Min.   :0.000    Min.   :0.000    Min.   :0.000       \n",
       " 1st Qu.:0.000           1st Qu.:0.000    1st Qu.:0.000    1st Qu.:0.000       \n",
       " Median :0.000           Median :0.000    Median :0.000    Median :0.000       \n",
       " Mean   :0.014           Mean   :0.036    Mean   :0.002    Mean   :0.002       \n",
       " 3rd Qu.:0.000           3rd Qu.:0.000    3rd Qu.:0.000    3rd Qu.:0.000       \n",
       " Max.   :1.000           Max.   :1.000    Max.   :1.000    Max.   :1.000       \n",
       " content_rating_Not Rated content_rating_PG content_rating_PG-13\n",
       " Min.   :0.000            Min.   :0.00      Min.   :0.000       \n",
       " 1st Qu.:0.000            1st Qu.:0.00      1st Qu.:0.000       \n",
       " Median :0.000            Median :0.00      Median :0.000       \n",
       " Mean   :0.022            Mean   :0.13      Mean   :0.286       \n",
       " 3rd Qu.:0.000            3rd Qu.:0.00      3rd Qu.:1.000       \n",
       " Max.   :1.000            Max.   :1.00      Max.   :1.000       \n",
       " content_rating_Passed content_rating_R content_rating_TV-14\n",
       " Min.   :0.000         Min.   :0.000    Min.   :0.000       \n",
       " 1st Qu.:0.000         1st Qu.:0.000    1st Qu.:0.000       \n",
       " Median :0.000         Median :0.000    Median :0.000       \n",
       " Mean   :0.001         Mean   :0.421    Mean   :0.003       \n",
       " 3rd Qu.:0.000         3rd Qu.:1.000    3rd Qu.:0.000       \n",
       " Max.   :1.000         Max.   :1.000    Max.   :1.000       \n",
       " content_rating_TV-G content_rating_TV-MA content_rating_TV-PG\n",
       " Min.   :0.000       Min.   :0.000        Min.   :0.000       \n",
       " 1st Qu.:0.000       1st Qu.:0.000        1st Qu.:0.000       \n",
       " Median :0.000       Median :0.000        Median :0.000       \n",
       " Mean   :0.001       Mean   :0.007        Mean   :0.002       \n",
       " 3rd Qu.:0.000       3rd Qu.:0.000        3rd Qu.:0.000       \n",
       " Max.   :1.000       Max.   :1.000        Max.   :1.000       \n",
       " content_rating_Unrated content_rating_X\n",
       " Min.   :0.000          Min.   :0.000   \n",
       " 1st Qu.:0.000          1st Qu.:0.000   \n",
       " Median :0.000          Median :0.000   \n",
       " Mean   :0.009          Mean   :0.005   \n",
       " 3rd Qu.:0.000          3rd Qu.:0.000   \n",
       " Max.   :1.000          Max.   :1.000   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other predictive models\n",
    "\n",
    "Other models could be used, for example support vector machines, neural networks, K-nearest neighbors (using the `svm`, `nnt`or `lazy` (! predict()$h ) functions from the `e1071`, `nnet` or `lazy` packages, respectively). Note that scaling the data is usually necessary when using neural networks and K-nearest neighbors approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnet (size=5)\n",
    "  non linear function gives the output, and goes from 0 to 1. We want a grade between 0 and 10 so we need to give a linear fct at the output by using linout=T\n",
    "  range of the values are quite different => nnet and nearrst neighbour are really bad when this happens so we have to normalize/scale the data scale(X)\n",
    "scale gives a matrix and not a dataframe => X<-dataframe(scale(X)) (see function scale for more details on what it does)\n",
    "\n",
    "see sample\n",
    "    \n",
    "    when you scale you have to use the mean and variance obtained from the scale of the training data for your test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
