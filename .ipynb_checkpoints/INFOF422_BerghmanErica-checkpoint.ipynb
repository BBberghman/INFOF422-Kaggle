{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# INFO F422 - Statistical Fundation of Machine Learning\n",
    "## Project \"House Prices : Advanced Regression Techniques\"\n",
    "\n",
    "    Erica Berghman\n",
    "    Master 1 - Brussels Engineer School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "\n",
    "* with dataset description, goals, and an overview of the report structure \n",
    "\n",
    "Starting from a data set with 81 criteria about houses and their selling price, the goal is to create a model capable of predicting the price of other houses given some of these criterias. A good model description is a model that has been refined multiple types. This report will show the methodology used to construct a model for this particular problem. It is based on the methodology of the Chapter 6 of the syllabus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataSample = 400\n",
    "mean = T          # variable to determine if we use the mean or the median to replace the NA values\n",
    "set.seed(2)\n",
    "\n",
    "source(\"function/replaceNA.R\")\n",
    "# Hide warnings\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing the data set\n",
    "\n",
    "In order to get a model, the data must be preprocessed. Firstly we read the data given and we take a sample set of 400 houses out of the 1460. There is 81 criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data<-read.csv(\"input/train.csv\")\n",
    "data.sample<-data[sample(nrow(data),dataSample),]\n",
    "#dim(data.sample)\n",
    "#data[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical (factor) criterias are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factor_variables<-which(sapply(data.sample[1,],class)==\"factor\")\n",
    "data.sample.nofactor<-data.sample[,-factor_variables]\n",
    "data.sample.factor<-data.sample[,factor_variables]\n",
    "#summary(data.sample.factor)\n",
    "\n",
    "library(dummies)\n",
    "variable_to_keep<-c(\"CentralAir\", \"Street\", \"LotShape\")\n",
    "data_factor_onehot <- dummy.data.frame(data.sample.factor[,variable_to_keep], sep=\"_\")\n",
    "data.nofactor.extended<-cbind(data.sample.nofactor,data_factor_onehot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing data \n",
    "The missing values (NA) are replaced by an estimator of these values (eg. mean or median).Ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (mean) {\n",
    "    data_preprocessed<-data.frame(apply(data.nofactor.extended,2,replace_na_with_mean_value)) \n",
    "} else {\n",
    "    data_preprocessed<-data.frame(apply(data.nofactor.extended,2,replace_na_with_median_value))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature selection \n",
    "Methodology and main results\n",
    "\n",
    "The text must contain the list of selected variables and the motivation of their choice. The use of formulas, tables and pseudo-code to describe the feature selection procedure is encouraged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redundant and irrelevant features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Id\" column which is irrelevant is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "FALSE"
      ],
      "text/latex": [
       "FALSE"
      ],
      "text/markdown": [
       "FALSE"
      ],
      "text/plain": [
       "[1] FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_preprocessed<-data_preprocessed[,setdiff(colnames(data_preprocessed),\"Id\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The criterias that are redundant (linear combination of others criterias and correlation > 0.99) are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(ggplot2)\n",
    "library(lattice)\n",
    "\n",
    "linearCombo.idx <- findLinearCombos(data_preprocessed)$remove\n",
    "if (!is.null(linearCombo.idx)) data_preprocessed<-data_preprocessed[,-linearCombo.idx]\n",
    "\n",
    "correlation.matrix <- cor(data_preprocessed)\n",
    "correlation.matrix[upper.tri(correlation.matrix)] <- 0\n",
    "diag(correlation.matrix) <- 0\n",
    "data.uncorrelated <- data_preprocessed[,!apply(correlation.matrix,2,function(x) any(abs(x) > 0.99))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X <- data.uncorrelated[,setdiff(colnames(data.uncorrelated),\"SalePrice\")]\n",
    "Y <- data.uncorrelated[,\"SalePrice\"]\n",
    "X <- data.frame(X)\n",
    "#Y <- data.frame(Y)\n",
    "X.scale <- data.frame(scale(X))\n",
    "Y.scale <- scale(Y)\n",
    "\n",
    "N<-nrow(X)    #Number of examples\n",
    "n<-ncol(X)    #Number of input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two feature selection methods are implemented in the featureSelection file:\n",
    "\n",
    "** 1. Filter method using correlation with the variable to determine.**\n",
    "\n",
    "   It create a subset of features, removing from the whole features set the ones less likely to determine the variable (SalePrice). It is robust to overfitting and effective in computational time. However it might select redundant variables as the interraction between the variables is not taken in consideration.  \n",
    "   \n",
    "** 2. Wrapper method**\n",
    "\n",
    "   Its a cyclic method where a subset of variable is created and evaluated by the Learning Algorithm, modifying the chosen subset. This is done until the best subset is generated.  \n",
    "    \n",
    "The filter method is used to select a first \"big\" set of features, that is then refined by the wrapper method. This gives us the possibility use advantages of both method to get a good subset in a relatively correct computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source(\"function/featureSelection.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.filtre <- filtre(X.scale,Y.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.mrmr <- mrmr(X.scale, Y.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"# features:  1   CV error =  0.2335   std dev =  0.1119\"     \n",
      " [2] \"# features:  2   CV error =  0.2357   std dev =  0.1134\"     \n",
      " [3] \"# features:  3   CV error =  0.2074   std dev =  0.0958\"     \n",
      " [4] \"# features:  4   CV error =  0.2101   std dev =  0.0961\"     \n",
      " [5] \"# features:  5   CV error =  0.2136   std dev =  0.0981\"     \n",
      " [6] \"# features:  6   CV error =  0.2219   std dev =  0.1057\"     \n",
      " [7] \"# features:  7   CV error =  0.219   std dev =  0.119\"       \n",
      " [8] \"# features:  8   CV error =  0.212   std dev =  0.108\"       \n",
      " [9] \"# features:  9   CV error =  0.2147   std dev =  0.1119\"     \n",
      "[10] \"# features:  10   CV error =  0.2182   std dev =  0.1125\"    \n",
      "[11] \"# features:  11   CV error =  0.206   std dev =  0.0964\"     \n",
      "[12] \"# features:  12   CV error =  0.2133   std dev =  0.1024\"    \n",
      "[13] \"# features:  13   CV error =  0.1939   std dev =  0.0794\"    \n",
      "[14] \"# features:  14   CV error =  0.2088   std dev =  0.1123\"    \n",
      "[15] \"# features:  15   CV error =  0.2095   std dev =  0.1126\"    \n",
      "[16] \"# features:  16   CV error =  0.1953   std dev =  0.0764\"    \n",
      "[17] \"# features:  17   CV error =  0.1678   std dev =  0.0619\"    \n",
      "[18] \"# features:  18   CV error =  0.1671   std dev =  0.0537\"    \n",
      "[19] \"# features:  19   CV error =  0.1937   std dev =  0.0946\"    \n",
      "[20] \"# features:  20   CV error =  0.1857   std dev =  0.0785\"    \n",
      "[21] \"# features:  21   CV error =  0.188   std dev =  0.0836\"     \n",
      "[22] \"# features:  22   CV error =  0.2561   std dev =  0.2152\"    \n",
      "[23] \"# features:  23   CV error =  0.2219   std dev =  0.1772\"    \n",
      "[24] \"# features:  24   CV error =  0.3484   std dev =  0.4779\"    \n",
      "[25] \"# features:  25   CV error =  0.3537   std dev =  0.4637\"    \n",
      "[26] \"# features:  26   CV error =  0.4649   std dev =  0.6722\"    \n",
      "[27] \"# features:  27   CV error =  0.5663   std dev =  0.8794\"    \n",
      "[28] \"# features:  28   CV error =  2.0156   std dev =  5.4678\"    \n",
      "[29] \"# features:  29   CV error =  1.7903   std dev =  4.5754\"    \n",
      "[30] \"# features:  30   CV error =  1.8188   std dev =  4.1287\"    \n",
      "[31] \"# features:  31   CV error =  2.5192   std dev =  5.7086\"    \n",
      "[32] \"# features:  32   CV error =  2.4124   std dev =  6.3515\"    \n",
      "[33] \"# features:  33   CV error =  5.4451   std dev =  11.2223\"   \n",
      "[34] \"# features:  34   CV error =  12.5002   std dev =  30.5954\"  \n",
      "[35] \"# features:  35   CV error =  10.4597   std dev =  24.7964\"  \n",
      "[36] \"# features:  36   CV error =  88.3667   std dev =  258.5095\" \n",
      "[37] \"# features:  37   CV error =  9.7448   std dev =  20.8549\"   \n",
      "[38] \"# features:  38   CV error =  170.3575   std dev =  528.7455\"\n",
      "[39] \"# features:  39   CV error =  170.3589   std dev =  528.745\" \n",
      "[1] \"18\"\n"
     ]
    }
   ],
   "source": [
    "features.pca <- pca(X.scale, Y.scale)\n",
    "#features.pca <- features.pca[,features.pca$nbfeatures]\n",
    "#colnames(X[features.pca])\n",
    "#colnames(X[features.pca[1:18]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Round  1  ; Selected feature:  4  ; CV error =  0.3546  ; std dev =  0.1468\"\n",
      "[1] \"Round  2  ; Selected feature:  12  ; CV error =  0.2557  ; std dev =  0.111\"\n",
      "[1] \"Round  3  ; Selected feature:  13  ; CV error =  0.2035  ; std dev =  0.0739\"\n",
      "[1] \"Round  4  ; Selected feature:  9  ; CV error =  0.1711  ; std dev =  0.062\"\n",
      "[1] \"Round  5  ; Selected feature:  7  ; CV error =  0.1569  ; std dev =  0.0602\"\n",
      "[1] \"Round  6  ; Selected feature:  2  ; CV error =  0.1489  ; std dev =  0.0534\"\n",
      "[1] \"Round  7  ; Selected feature:  19  ; CV error =  0.1434  ; std dev =  0.0492\"\n",
      "[1] \"Round  8  ; Selected feature:  11  ; CV error =  0.1374  ; std dev =  0.0436\"\n",
      "[1] \"Round  9  ; Selected feature:  20  ; CV error =  0.1352  ; std dev =  0.0431\"\n",
      "[1] \"Round  10  ; Selected feature:  24  ; CV error =  0.1335  ; std dev =  0.0422\"\n",
      "[1] \"Round  11  ; Selected feature:  31  ; CV error =  0.132  ; std dev =  0.0449\"\n",
      "[1] \"Round  12  ; Selected feature:  38  ; CV error =  0.1309  ; std dev =  0.0416\"\n",
      "[1] \"Round  13  ; Selected feature:  8  ; CV error =  0.13  ; std dev =  0.0453\"\n",
      "[1] \"Round  14  ; Selected feature:  10  ; CV error =  0.1294  ; std dev =  0.0465\"\n",
      "[1] \"Round  15  ; Selected feature:  23  ; CV error =  0.1288  ; std dev =  0.0462\"\n",
      "[1] \"Round  16  ; Selected feature:  1  ; CV error =  0.1282  ; std dev =  0.0472\"\n",
      "[1] \"Round  17  ; Selected feature:  5  ; CV error =  0.1279  ; std dev =  0.0481\"\n",
      "[1] \"Round  18  ; Selected feature:  34  ; CV error =  0.1277  ; std dev =  0.0473\"\n",
      "[1] \"Round  19  ; Selected feature:  39  ; CV error =  0.1278  ; std dev =  0.0475\"\n",
      "[1] \"Round  20  ; Selected feature:  36  ; CV error =  0.1279  ; std dev =  0.0473\"\n",
      "[1] \"Round  21  ; Selected feature:  32  ; CV error =  0.1281  ; std dev =  0.0472\"\n",
      "[1] \"Round  22  ; Selected feature:  16  ; CV error =  0.1282  ; std dev =  0.0468\"\n",
      "[1] \"Round  23  ; Selected feature:  28  ; CV error =  0.1286  ; std dev =  0.0472\"\n",
      "[1] \"Round  24  ; Selected feature:  21  ; CV error =  0.1291  ; std dev =  0.0481\"\n",
      "[1] \"Round  25  ; Selected feature:  30  ; CV error =  0.1293  ; std dev =  0.051\"\n",
      "[1] \"Round  26  ; Selected feature:  37  ; CV error =  0.1298  ; std dev =  0.0509\"\n",
      "[1] \"Round  27  ; Selected feature:  29  ; CV error =  0.1304  ; std dev =  0.0518\"\n",
      "[1] \"Round  28  ; Selected feature:  35  ; CV error =  0.131  ; std dev =  0.0517\"\n",
      "[1] \"Round  29  ; Selected feature:  6  ; CV error =  0.131  ; std dev =  0.0506\"\n",
      "[1] \"Round  30  ; Selected feature:  33  ; CV error =  0.1314  ; std dev =  0.0511\"\n",
      "[1] \"Round  31  ; Selected feature:  17  ; CV error =  0.1321  ; std dev =  0.0505\"\n",
      "[1] \"Round  32  ; Selected feature:  15  ; CV error =  0.1329  ; std dev =  0.0508\"\n",
      "[1] \"Round  33  ; Selected feature:  26  ; CV error =  0.1336  ; std dev =  0.0515\"\n",
      "[1] \"Round  34  ; Selected feature:  25  ; CV error =  0.1345  ; std dev =  0.0509\"\n",
      "[1] \"Round  35  ; Selected feature:  22  ; CV error =  0.1355  ; std dev =  0.0533\"\n",
      "[1] \"Round  36  ; Selected feature:  18  ; CV error =  0.1365  ; std dev =  0.0534\"\n",
      "[1] \"Round  37  ; Selected feature:  27  ; CV error =  0.1378  ; std dev =  0.0537\"\n",
      "[1] \"Round  38  ; Selected feature:  14  ; CV error =  0.1389  ; std dev =  0.0538\"\n",
      "[1] \"Round  39  ; Selected feature:  3  ; CV error =  0.1408  ; std dev =  0.058\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'OverallQual'</li>\n",
       "\t<li>'X1stFlrSF'</li>\n",
       "\t<li>'X2ndFlrSF'</li>\n",
       "\t<li>'BsmtFinSF1'</li>\n",
       "\t<li>'YearRemodAdd'</li>\n",
       "\t<li>'LotFrontage'</li>\n",
       "\t<li>'BedroomAbvGr'</li>\n",
       "\t<li>'BsmtUnfSF'</li>\n",
       "\t<li>'KitchenAbvGr'</li>\n",
       "\t<li>'GarageCars'</li>\n",
       "\t<li>'PoolArea'</li>\n",
       "\t<li>'LotShape_IR2'</li>\n",
       "\t<li>'MasVnrArea'</li>\n",
       "\t<li>'BsmtFinSF2'</li>\n",
       "\t<li>'GarageYrBlt'</li>\n",
       "\t<li>'MSSubClass'</li>\n",
       "\t<li>'OverallCond'</li>\n",
       "\t<li>'YrSold'</li>\n",
       "\t<li>'LotShape_IR3'</li>\n",
       "\t<li>'Street_Grvl'</li>\n",
       "\t<li>'MiscVal'</li>\n",
       "\t<li>'BsmtHalfBath'</li>\n",
       "\t<li>'EnclosedPorch'</li>\n",
       "\t<li>'TotRmsAbvGrd'</li>\n",
       "\t<li>'ScreenPorch'</li>\n",
       "\t<li>'LotShape_IR1'</li>\n",
       "\t<li>'X3SsnPorch'</li>\n",
       "\t<li>'CentralAir_Y'</li>\n",
       "\t<li>'YearBuilt'</li>\n",
       "\t<li>'MoSold'</li>\n",
       "\t<li>'FullBath'</li>\n",
       "\t<li>'BsmtFullBath'</li>\n",
       "\t<li>'WoodDeckSF'</li>\n",
       "\t<li>'GarageArea'</li>\n",
       "\t<li>'Fireplaces'</li>\n",
       "\t<li>'HalfBath'</li>\n",
       "\t<li>'OpenPorchSF'</li>\n",
       "\t<li>'LowQualFinSF'</li>\n",
       "\t<li>'LotArea'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'OverallQual'\n",
       "\\item 'X1stFlrSF'\n",
       "\\item 'X2ndFlrSF'\n",
       "\\item 'BsmtFinSF1'\n",
       "\\item 'YearRemodAdd'\n",
       "\\item 'LotFrontage'\n",
       "\\item 'BedroomAbvGr'\n",
       "\\item 'BsmtUnfSF'\n",
       "\\item 'KitchenAbvGr'\n",
       "\\item 'GarageCars'\n",
       "\\item 'PoolArea'\n",
       "\\item 'LotShape\\_IR2'\n",
       "\\item 'MasVnrArea'\n",
       "\\item 'BsmtFinSF2'\n",
       "\\item 'GarageYrBlt'\n",
       "\\item 'MSSubClass'\n",
       "\\item 'OverallCond'\n",
       "\\item 'YrSold'\n",
       "\\item 'LotShape\\_IR3'\n",
       "\\item 'Street\\_Grvl'\n",
       "\\item 'MiscVal'\n",
       "\\item 'BsmtHalfBath'\n",
       "\\item 'EnclosedPorch'\n",
       "\\item 'TotRmsAbvGrd'\n",
       "\\item 'ScreenPorch'\n",
       "\\item 'LotShape\\_IR1'\n",
       "\\item 'X3SsnPorch'\n",
       "\\item 'CentralAir\\_Y'\n",
       "\\item 'YearBuilt'\n",
       "\\item 'MoSold'\n",
       "\\item 'FullBath'\n",
       "\\item 'BsmtFullBath'\n",
       "\\item 'WoodDeckSF'\n",
       "\\item 'GarageArea'\n",
       "\\item 'Fireplaces'\n",
       "\\item 'HalfBath'\n",
       "\\item 'OpenPorchSF'\n",
       "\\item 'LowQualFinSF'\n",
       "\\item 'LotArea'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'OverallQual'\n",
       "2. 'X1stFlrSF'\n",
       "3. 'X2ndFlrSF'\n",
       "4. 'BsmtFinSF1'\n",
       "5. 'YearRemodAdd'\n",
       "6. 'LotFrontage'\n",
       "7. 'BedroomAbvGr'\n",
       "8. 'BsmtUnfSF'\n",
       "9. 'KitchenAbvGr'\n",
       "10. 'GarageCars'\n",
       "11. 'PoolArea'\n",
       "12. 'LotShape_IR2'\n",
       "13. 'MasVnrArea'\n",
       "14. 'BsmtFinSF2'\n",
       "15. 'GarageYrBlt'\n",
       "16. 'MSSubClass'\n",
       "17. 'OverallCond'\n",
       "18. 'YrSold'\n",
       "19. 'LotShape_IR3'\n",
       "20. 'Street_Grvl'\n",
       "21. 'MiscVal'\n",
       "22. 'BsmtHalfBath'\n",
       "23. 'EnclosedPorch'\n",
       "24. 'TotRmsAbvGrd'\n",
       "25. 'ScreenPorch'\n",
       "26. 'LotShape_IR1'\n",
       "27. 'X3SsnPorch'\n",
       "28. 'CentralAir_Y'\n",
       "29. 'YearBuilt'\n",
       "30. 'MoSold'\n",
       "31. 'FullBath'\n",
       "32. 'BsmtFullBath'\n",
       "33. 'WoodDeckSF'\n",
       "34. 'GarageArea'\n",
       "35. 'Fireplaces'\n",
       "36. 'HalfBath'\n",
       "37. 'OpenPorchSF'\n",
       "38. 'LowQualFinSF'\n",
       "39. 'LotArea'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"OverallQual\"   \"X1stFlrSF\"     \"X2ndFlrSF\"     \"BsmtFinSF1\"   \n",
       " [5] \"YearRemodAdd\"  \"LotFrontage\"   \"BedroomAbvGr\"  \"BsmtUnfSF\"    \n",
       " [9] \"KitchenAbvGr\"  \"GarageCars\"    \"PoolArea\"      \"LotShape_IR2\" \n",
       "[13] \"MasVnrArea\"    \"BsmtFinSF2\"    \"GarageYrBlt\"   \"MSSubClass\"   \n",
       "[17] \"OverallCond\"   \"YrSold\"        \"LotShape_IR3\"  \"Street_Grvl\"  \n",
       "[21] \"MiscVal\"       \"BsmtHalfBath\"  \"EnclosedPorch\" \"TotRmsAbvGrd\" \n",
       "[25] \"ScreenPorch\"   \"LotShape_IR1\"  \"X3SsnPorch\"    \"CentralAir_Y\" \n",
       "[29] \"YearBuilt\"     \"MoSold\"        \"FullBath\"      \"BsmtFullBath\" \n",
       "[33] \"WoodDeckSF\"    \"GarageArea\"    \"Fireplaces\"    \"HalfBath\"     \n",
       "[37] \"OpenPorchSF\"   \"LowQualFinSF\"  \"LotArea\"      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.wrapper <- wrapper(X.scale, Y.scale)\n",
    "colnames(X[features.wrapper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.wrapper.pca <- wrapper(X.pca, Y.pca)\n",
    "colnames(X[features.wrapper.pca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection  \n",
    "Methodology and main results\n",
    "\n",
    "For the learning method, the only packages that may be used are those seen during the exercise classes : stats, nnet, tree, lazy, and e1071, for linear models, neural networks, decision trees, nearest neighbours and SVM, respectively.\n",
    "\n",
    "The accuracy of the regression models during the selection process should be assessed by using the root mean squared error between the logarithm of the\n",
    "predicted value and the logarithm of the observed sale price.\n",
    "\n",
    "The text must mention the different\n",
    "(and at least three) models which have been taken into consideration and the procedure used for model assessment and selection. The use of formulas,\n",
    "tables and pseudo-code to describe the feature selection procedure is encouraged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble techniques : Combination of models strategy\n",
    "Methodology and main results\n",
    "\n",
    "The text should mention the different models taken into consideration as well as the techniques used for the combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and conclusion: \n",
    "Summary of your work, and discussion of what worked well, not well, why, what insights you got from the analyses you made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir33"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
