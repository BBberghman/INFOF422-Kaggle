{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# INFO F422 - Statistical Fundation of Machine Learning\n",
    "## Project \"House Prices : Advanced Regression Techniques\"\n",
    "\n",
    "    Erica Berghman\n",
    "    Master 1 - Brussels Engineer School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "\n",
    "* with dataset description, goals, and an overview of the report structure \n",
    "\n",
    "Starting from a data set with 81 criteria about houses and their selling price, the goal is to create a model capable of predicting the price of other houses given some of these criterias. A good model description is a model that has been refined multiple types. This report will show the methodology used to construct a model for this particular problem. It is based on the methodology of the Chapter 6 of the syllabus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataSample = 400\n",
    "mean = T          # variable to determine if we use the mean or the median to replace the NA values\n",
    "set.seed(2)\n",
    "\n",
    "source(\"function/replaceNA.R\")\n",
    "# Hide warnings\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing the data set\n",
    "\n",
    "In order to get a model, the data must be preprocessed. Firstly we read the data given and we take a sample set of 400 houses out of the 1460. There is 81 criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data<-read.csv(\"input/train.csv\")\n",
    "data.sample<-data[sample(nrow(data),dataSample),]\n",
    "#dim(data.sample)\n",
    "#data[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical (factor) criterias are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factor_variables<-which(sapply(data.sample[1,],class)==\"factor\")\n",
    "data.sample.nofactor<-data.sample[,-factor_variables]\n",
    "data.sample.factor<-data.sample[,factor_variables]\n",
    "#summary(data.sample.factor)\n",
    "\n",
    "library(dummies)\n",
    "variable_to_keep<-c(\"CentralAir\", \"Street\", \"LotShape\")\n",
    "data_factor_onehot <- dummy.data.frame(data.sample.factor[,variable_to_keep], sep=\"_\")\n",
    "data.nofactor.extended<-cbind(data.sample.nofactor,data_factor_onehot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing data \n",
    "The missing values (NA) are replaced by an estimator of these values (eg. mean or median).Ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (mean) {\n",
    "    data_preprocessed<-data.frame(apply(data.nofactor.extended,2,replace_na_with_mean_value)) \n",
    "} else {\n",
    "    data_preprocessed<-data.frame(apply(data.nofactor.extended,2,replace_na_with_median_value))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature selection \n",
    "Methodology and main results\n",
    "\n",
    "The text must contain the list of selected variables and the motivation of their choice. The use of formulas, tables and pseudo-code to describe the feature selection procedure is encouraged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redundant and irrelevant features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Id\" column which is irrelevant is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_preprocessed<-data_preprocessed[,setdiff(colnames(data_preprocessed),\"Id\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The criterias that are redundant (linear combination of others criterias and correlation > 0.99) are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(ggplot2)\n",
    "library(lattice)\n",
    "\n",
    "linearCombo.idx <- findLinearCombos(data_preprocessed)$remove\n",
    "if (!is.null(linearCombo.idx)) data_preprocessed<-data_preprocessed[,-linearCombo.idx]\n",
    "\n",
    "correlation.matrix <- cor(data_preprocessed)\n",
    "correlation.matrix[upper.tri(correlation.matrix)] <- 0\n",
    "diag(correlation.matrix) <- 0\n",
    "data.uncorrelated <- data_preprocessed[,!apply(correlation.matrix,2,function(x) any(abs(x) > 0.99))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output vectors are created and scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X <- data.uncorrelated[,setdiff(colnames(data.uncorrelated),\"SalePrice\")]\n",
    "Y <- data.uncorrelated[,\"SalePrice\"]\n",
    "X <- data.frame(X)\n",
    "#Y <- data.frame(Y)\n",
    "X.scale <- data.frame(scale(X))\n",
    "Y.scale <- scale(Y)\n",
    "\n",
    "N<-nrow(X)    #Number of examples\n",
    "n<-ncol(X)    #Number of input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source(\"function/featureSelection.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two feature selection methods are implemented in the featureSelection file:\n",
    "\n",
    "** 1. Filter method using correlation with the variable to determine.**\n",
    "\n",
    "   It create a subset of features, removing from the whole features set the ones less likely to determine the variable (SalePrice). It is robust to overfitting and effective in computational time. However it might select redundant variables as the interraction between the variables is not taken in consideration.  \n",
    "   \n",
    "** 2. Wrapper method**\n",
    "\n",
    "   Its a cyclic method where a subset of variable is created and evaluated by the Learning Algorithm, modifying the chosen subset. This is done until the best subset is generated.  \n",
    "    \n",
    "The filter method is used to select a first \"big\" set of features, that is then refined by the wrapper method. This gives us the possibility use advantages of both method to get a good subset in a relatively correct computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "32"
      ],
      "text/latex": [
       "32"
      ],
      "text/markdown": [
       "32"
      ],
      "text/plain": [
       "[1] 32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.filtre <- filtre(X.scale,Y.scale)  # return the idx of the more correlated features where #feature = argmin(CV error)\n",
    "length(features.filtre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "39"
      ],
      "text/latex": [
       "39"
      ],
      "text/markdown": [
       "39"
      ],
      "text/plain": [
       "[1] 39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.mrmr <- mrmr(X.scale, Y.scale)    # return the idx of the more correlated features where #feature = argmin(CV error)\n",
    "length(features.mrmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 400  39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>PC1</th><th scope=col>PC2</th><th scope=col>PC3</th><th scope=col>PC4</th><th scope=col>PC5</th><th scope=col>PC6</th><th scope=col>PC7</th><th scope=col>PC8</th><th scope=col>PC9</th><th scope=col>PC10</th><th scope=col>PC11</th><th scope=col>PC12</th><th scope=col>PC13</th><th scope=col>PC14</th><th scope=col>PC15</th><th scope=col>PC16</th><th scope=col>PC17</th><th scope=col>PC18</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>270</th><td>-0.1699082 </td><td>1.563452   </td><td>-0.4343646 </td><td>-0.7174866 </td><td>-0.5534796 </td><td>1.2414134  </td><td>-0.8891932 </td><td> 0.72442332</td><td>-0.2648589 </td><td>-0.7364867 </td><td>-0.3635866 </td><td> 0.7121533 </td><td> 0.9225456 </td><td>-0.4096088 </td><td>-0.03577096</td><td> 0.2867537 </td><td> 1.0635186 </td><td> 0.783415  </td></tr>\n",
       "\t<tr><th scope=row>1025</th><td>-2.0445371 </td><td>2.085179   </td><td>-3.4221451 </td><td> 0.7942827 </td><td> 1.7858386 </td><td>0.9426973  </td><td> 1.1377662 </td><td>-0.02839457</td><td> 1.2208718 </td><td>-0.3501392 </td><td>-1.1492037 </td><td>-0.2093078 </td><td>-1.1077119 </td><td>-0.9058846 </td><td> 1.06563427</td><td>-0.9751243 </td><td>-0.2545433 </td><td>-1.297939  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllll}\n",
       "  & PC1 & PC2 & PC3 & PC4 & PC5 & PC6 & PC7 & PC8 & PC9 & PC10 & PC11 & PC12 & PC13 & PC14 & PC15 & PC16 & PC17 & PC18\\\\\n",
       "\\hline\n",
       "\t270 & -0.1699082  & 1.563452    & -0.4343646  & -0.7174866  & -0.5534796  & 1.2414134   & -0.8891932  &  0.72442332 & -0.2648589  & -0.7364867  & -0.3635866  &  0.7121533  &  0.9225456  & -0.4096088  & -0.03577096 &  0.2867537  &  1.0635186  &  0.783415  \\\\\n",
       "\t1025 & -2.0445371  & 2.085179    & -3.4221451  &  0.7942827  &  1.7858386  & 0.9426973   &  1.1377662  & -0.02839457 &  1.2208718  & -0.3501392  & -1.1492037  & -0.2093078  & -1.1077119  & -0.9058846  &  1.06563427 & -0.9751243  & -0.2545433  & -1.297939  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | PC1 | PC2 | PC3 | PC4 | PC5 | PC6 | PC7 | PC8 | PC9 | PC10 | PC11 | PC12 | PC13 | PC14 | PC15 | PC16 | PC17 | PC18 | \n",
       "|---|---|\n",
       "| 270 | -0.1699082  | 1.563452    | -0.4343646  | -0.7174866  | -0.5534796  | 1.2414134   | -0.8891932  |  0.72442332 | -0.2648589  | -0.7364867  | -0.3635866  |  0.7121533  |  0.9225456  | -0.4096088  | -0.03577096 |  0.2867537  |  1.0635186  |  0.783415   | \n",
       "| 1025 | -2.0445371  | 2.085179    | -3.4221451  |  0.7942827  |  1.7858386  | 0.9426973   |  1.1377662  | -0.02839457 |  1.2208718  | -0.3501392  | -1.1492037  | -0.2093078  | -1.1077119  | -0.9058846  |  1.06563427 | -0.9751243  | -0.2545433  | -1.297939   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     PC1        PC2      PC3        PC4        PC5        PC6       PC7       \n",
       "270  -0.1699082 1.563452 -0.4343646 -0.7174866 -0.5534796 1.2414134 -0.8891932\n",
       "1025 -2.0445371 2.085179 -3.4221451  0.7942827  1.7858386 0.9426973  1.1377662\n",
       "     PC8         PC9        PC10       PC11       PC12       PC13      \n",
       "270   0.72442332 -0.2648589 -0.7364867 -0.3635866  0.7121533  0.9225456\n",
       "1025 -0.02839457  1.2208718 -0.3501392 -1.1492037 -0.2093078 -1.1077119\n",
       "     PC14       PC15        PC16       PC17       PC18     \n",
       "270  -0.4096088 -0.03577096  0.2867537  1.0635186  0.783415\n",
       "1025 -0.9058846  1.06563427 -0.9751243 -0.2545433 -1.297939"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>400</li>\n",
       "\t<li>18</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 400\n",
       "\\item 18\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 400\n",
       "2. 18\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 400  18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.pca <- pca(X.scale, Y.scale)   # return X_pca with nb of columns = argmin(CV error)\n",
    "X.pca[1:2,]\n",
    "dim(X.pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.wrapper <- wrapper(X.scale, Y.scale)\n",
    "X[1:2,features.wrapper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.wrapper.pca <- wrapper(X.pca, Y.pca)\n",
    "colnames(X[features.wrapper.pca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection  \n",
    "Methodology and main results\n",
    "\n",
    "For the learning method, the only packages that may be used are those seen during the exercise classes : stats, nnet, tree, lazy, and e1071, for linear models, neural networks, decision trees, nearest neighbours and SVM, respectively.\n",
    "\n",
    "The accuracy of the regression models during the selection process should be assessed by using the root mean squared error between the logarithm of the\n",
    "predicted value and the logarithm of the observed sale price.\n",
    "\n",
    "The text must mention the different\n",
    "(and at least three) models which have been taken into consideration and the procedure used for model assessment and selection. The use of formulas,\n",
    "tables and pseudo-code to describe the feature selection procedure is encouraged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble techniques : Combination of models strategy\n",
    "Methodology and main results\n",
    "\n",
    "The text should mention the different models taken into consideration as well as the techniques used for the combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and conclusion: \n",
    "Summary of your work, and discussion of what worked well, not well, why, what insights you got from the analyses you made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir33"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
